{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf40763-305d-44f8-85dc-1586bd7bbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.pix2pix_turbo import Pix2Pix_Turbo\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e436360e-734d-4112-8171-abc4aaa3e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    0: 'output/pix2pix_turbo/angel_0_go/checkpoints/model_1001.pkl', # 180.44\n",
    "    1: 'output/pix2pix_turbo/angel_augmentation2_1/checkpoints/best_model.pkl', # 185.57\n",
    "    2: 'output/pix2pix_turbo/angel_2/checkpoints/model_2001.pkl', # 218.61\n",
    "    3: 'output/pix2pix_turbo/angel_augmentation_3/checkpoints/best_model.pkl', # 193.63\n",
    "    4: 'output/pix2pix_turbo/angel_4/checkpoints/model_4501.pkl', # 187.45\n",
    "    5: 'output/pix2pix_turbo/angel_5/checkpoints/model_3001.pkl' # 173.64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97382529-41ba-4b05-bec8-97e89d616d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = 'data/oct/validation_set/val/CF/'\n",
    "dst_dir = 'data/oct/generated_OCT_images_DIR'\n",
    "dst_512_dir = 'data/oct/generated_OCT_images_DIR_512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368d01ff-3b62-4ab8-9e0c-c85c53351b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model_index, src_dir, dst_dir, dst_512_dir):\n",
    "    model = Pix2Pix_Turbo(pretrained_path=models[model_index])\n",
    "    model.set_eval()\n",
    "    #model.half()\n",
    "\n",
    "    for _, dirs, files in os.walk(src_dir):\n",
    "        \n",
    "        for f in files:\n",
    "            f_path = os.path.join(src_dir, f)\n",
    "            input_image = Image.open(f_path).convert('RGB')\n",
    "            new_width = input_image.width - input_image.width % 8\n",
    "            new_height = input_image.height - input_image.height % 8\n",
    "            input_image = input_image.resize((512, 512), Image.LANCZOS)\n",
    "            bname = os.path.basename(f)\n",
    "\n",
    "            # translate the image\n",
    "            with torch.no_grad():\n",
    "                c_t = F.to_tensor(input_image).unsqueeze(0).cuda()\n",
    "                #c_t = c_t.half()\n",
    "                if 'L' in f:\n",
    "                    test_prompts = \"This is the color fundus image of left eye, please generate corresponding optical coherence tomography(OCT) image\"\n",
    "                else:\n",
    "                    test_prompts = \"This is the color fundus image of right eye, please generate corresponding optical coherence tomography(OCT) image\"\n",
    "\n",
    "                output_image = model(c_t, test_prompts)\n",
    "                output_pil = transforms.ToPILImage()(output_image[0].cpu() * 0.5 + 0.5)\n",
    "                \n",
    "            dst_dir_path = os.path.join(dst_dir, bname.split('.')[0])\n",
    "            dst_512_dir_path = os.path.join(dst_512_dir, bname.split('.')[0])\n",
    "            if not os.path.exists(dst_dir_path):\n",
    "                os.makedirs(dst_dir_path)\n",
    "            if not os.path.exists(dst_512_dir_path):\n",
    "                os.makedirs(dst_512_dir_path)\n",
    "            output_pil.save(os.path.join(dst_512_dir_path, f\"{bname.split('.')[0]}_{model_index}.jpg\"))\n",
    "            output_pil = output_pil.resize((448, 320), Image.LANCZOS)\n",
    "            output_pil.save(os.path.join(dst_dir_path, f\"{bname.split('.')[0]}_{model_index}.jpg\"))\n",
    "    model.release_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7ad1b7-908f-4b90-ba12-5c4d6109522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model with OWN weights\n"
     ]
    }
   ],
   "source": [
    "generate_images(3, src_dir, dst_dir, dst_512_dir+'_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac96d19-3de9-4259-98c9-8666c1dd7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_sequence(model_index, src_dir, dst_dir, dst_512_dir):\n",
    "    \"\"\"\n",
    "    Generate images sequence using Pix2Pix_Turbo model and save the outputs.\n",
    "\n",
    "    Args:\n",
    "        model_index (int): Index of the model in the `models` list.\n",
    "        src_dir (str): Path to the source directory containing input images.\n",
    "        dst_dir (str): Path to the destination directory for resized images.\n",
    "        dst_512_dir (str): Path to the destination directory for 512x512 images.\n",
    "    \"\"\"\n",
    "    print(f\"Loading model: {models[model_index]}\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = Pix2Pix_Turbo(pretrained_path=models[model_index])\n",
    "    model.set_eval()\n",
    "\n",
    "    # Walk through the source directory\n",
    "    for root, _, files in os.walk(src_dir):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(root, file_name)\n",
    "\n",
    "            # Ensure the file is an image\n",
    "            if not file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                print(f\"Skipping non-image file: {file_name}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Load and preprocess the input image\n",
    "                input_image = Image.open(file_path).convert('RGB')\n",
    "                base_name = os.path.basename(file_name).split('_')[0]\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    # Convert image to tensor and move to GPU\n",
    "                    c_t = F.to_tensor(input_image).unsqueeze(0).cuda()\n",
    "                    test_prompt = \"generate OCT images rotated 30 degrees clockwise\"\n",
    "\n",
    "                    # Generate output using the model\n",
    "                    output_tensor = model(c_t, test_prompt)\n",
    "                    output_pil = transforms.ToPILImage()(output_tensor[0].cpu() * 0.5 + 0.5)\n",
    "\n",
    "                # Save the 512x512 output\n",
    "                dst_512_path = os.path.join(dst_512_dir, base_name)\n",
    "                os.makedirs(dst_512_path, exist_ok=True)\n",
    "                output_pil.save(os.path.join(dst_512_path, f\"{base_name}_{model_index}.jpg\"))\n",
    "\n",
    "                # Resize and save the 448x320 output\n",
    "                resized_output = output_pil.resize((448, 320), Image.LANCZOS)\n",
    "                dst_resized_path = os.path.join(dst_dir, base_name)\n",
    "                os.makedirs(dst_resized_path, exist_ok=True)\n",
    "                resized_output.save(os.path.join(dst_resized_path, f\"{base_name}_{model_index}.jpg\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "    # Release model memory\n",
    "    model.release_memory()\n",
    "    print(\"Model memory released.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556442c8-a654-46cc-a0c3-76b5f6285ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: output/pix2pix_turbo/sequence_angel_1/checkpoints/best_model.pkl\n",
      "Initializing model with OWN weights\n",
      "Model memory released.\n",
      "Loading model: output/pix2pix_turbo/sequence_angel_2/checkpoints/best_model.pkl\n",
      "Initializing model with OWN weights\n",
      "Model memory released.\n",
      "Loading model: output/pix2pix_turbo/sequence_angel_3/checkpoints/best_model.pkl\n",
      "Initializing model with OWN weights\n",
      "Model memory released.\n",
      "Loading model: output/pix2pix_turbo/sequence_angel_4/checkpoints/best_model.pkl\n",
      "Initializing model with OWN weights\n",
      "Model memory released.\n",
      "Loading model: output/pix2pix_turbo/sequence_angel_5/checkpoints/best_model.pkl\n",
      "Initializing model with OWN weights\n",
      "Model memory released.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    generate_images_sequence(i, dst_512_dir + f'_{i-1}', dst_dir, dst_512_dir + f'_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacea418-c362-4bc8-97f8-878ddb258d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'data/oct/generated_OCT_images_DIR' has been compressed into 'submit_data.zip'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_directory(folder_path, output_zip):\n",
    "    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # 获取文件的完整路径\n",
    "                file_path = os.path.join(root, file)\n",
    "                # 在压缩包中存储的路径，去除父目录路径部分\n",
    "                arcname = os.path.relpath(file_path, start=folder_path)\n",
    "                # 添加文件到压缩包中\n",
    "                zipf.write(file_path, arcname)\n",
    "    print(f\"Folder '{folder_path}' has been compressed into '{output_zip}'\")\n",
    "\n",
    "# 使用示例\n",
    "zip_directory(\"data/oct/generated_OCT_images_DIR\", \"submit_data.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1a088-6bb2-45dd-9eea-1e6873f627a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
